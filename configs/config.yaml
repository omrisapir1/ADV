model:
  llm_name: Qwen/Qwen2.5-Math-1.5B-Instruct
  rm_name: nvidia/AceMath-7B-RM

reward_model:
  rm_reference_batch_size: 32

dataset:
  name: omrisap/NuminaMath-5K-TreeRPO            # e.g. "your-username/your-math-dataset" or local path
  split: train
  field_question: problem
  field_answer: final_answer

generation:
  n_samples_per_problem: 96
  max_new_tokens: 2048
  temperature: 1.3
  top_p: 0.96
  top_k: 200
  repetition_penalty: 1.1

vllm:
  gpu_memory_utilization: 0.2
  max_num_seqs: 64
  max_num_batched_tokens: 32768


hardware:
  llm_gpu_id: 0
  rm_gpu_id: 1

train:
  batch_size: 2
  num_steps: 100
