model:
  llm_name: Qwen/Qwen2.5-Math-1.5B-Instruct
  rm_name: nvidia/AceMath-7B-RM

reward_model:
  reference_batch_size: 480
  optim:
    name: adamw
    lr: 2e-5
    weight_decay: 0.01
    betas: [ 0.9, 0.999 ]
    eps: 1.0e-8
    fused: true
    no_decay_modules: [ "LayerNorm", "bias" ]
  scheduler:
      name: linear
      warmup_ratio: 0.03
  train:
    batch_size: 16
    grad_clip: 1.0
    grad_accum: 1
    mixed_precision: bf16
    log_every: 10
    save_every: 500
    out_dir: /workspace/ADV/checkpoints/rm


dataset:
  name: omrisap/NuminaMath-5K-TreeRPO            # e.g. "your-username/your-math-dataset" or local path
  split: train
  field_question: problem
  field_answer: final_answer

generation:
  n_samples_per_problem: 96
  max_new_tokens: 1024
  temperature: 1.3
  top_p: 0.96
  top_k: 200
  repetition_penalty: 1.1

vllm:
  gpu_memory_utilization: 0.7
  max_num_seqs: 512
  max_num_batched_tokens: 150000


hardware:
  llm_gpu_id: 0
  rm_gpu_id: 1

train:
  batch_size: 16
  num_steps: 100
